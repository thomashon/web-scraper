{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:05:08.258448Z",
     "start_time": "2019-07-27T22:04:59.520455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\thoma\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\thoma\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import time as t\n",
    "import hashlib\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:05:50.230585Z",
     "start_time": "2019-07-27T22:05:08.268443Z"
    }
   },
   "outputs": [],
   "source": [
    "weekdays = ['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag', 'Sonntag']\n",
    "home = 'https://www.hall-tirol.at'\n",
    "event_site = '/veranstaltungen/'\n",
    "\n",
    "pages = []\n",
    "pages.append(home + event_site)\n",
    "response = requests.get(home + event_site)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "events = []\n",
    "\n",
    "for j in range(len(soup.select('.pageNaviLink'))):\n",
    "    pages.append(home + soup.select('.pageNaviLink')[j].attrs['href'])\n",
    "\n",
    "\n",
    "for page in pages:\n",
    "    t.sleep(3)\n",
    "    response = requests.get(page)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    items = soup.select('h3.listEntryTitle')\n",
    "    for item in items:\n",
    "        t.sleep(0.1)\n",
    "\n",
    "        try:\n",
    "            title = item.select_one('a').string\n",
    "        except: AttributeError\n",
    "\n",
    "        try:\n",
    "            date = soup.select('span.daydate.dayFrom')[i].string\n",
    "            date = datetime.datetime(int(date[6:]), int(date[3:5]), int(date[0:2]))\n",
    "            week_day = weekdays[pd.to_datetime(date).weekday()]\n",
    "        except: AttributeError \n",
    "\n",
    "        try:    \n",
    "            time = soup.select('span.timeFrom')[i].get_text().replace(', ', '')\n",
    "        except: AttributeError \n",
    "\n",
    "        try:\n",
    "            link = home + str(item.select_one('a').attrs['href'])\n",
    "        except: AttributeError \n",
    "\n",
    "        try:\n",
    "            location = soup.select('span.listEntryLocation')[i].string\n",
    "            if location == None or '':\n",
    "                location = 'Hall in Tirol'\n",
    "        except: AttributeError\n",
    "\n",
    "        try:\n",
    "            short = soup.select('div.listEntryDescription')[i].string.strip().replace('\\n', '')\n",
    "            short = short\n",
    "        except: AttributeError\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        hash = hashlib.sha256()\n",
    "        hash.update(bytes(title, 'utf-8'))\n",
    "        hash.update(bytes(location, 'utf-8'))\n",
    "        hash.update(bytes(str(date), 'utf-8'))\n",
    "        hash.update(bytes(str(time), 'utf-8'))\n",
    "\n",
    "        events.append({\n",
    "            \"name\": title,\n",
    "            \"date\": date,\n",
    "            \"location\": location,\n",
    "            \"link\": link,\n",
    "            \"short\": short,\n",
    "            \"source\": \"Region Hall in Tirol Homepage\",\n",
    "            \"identifier\": hash.hexdigest()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:06:08.789382Z",
     "start_time": "2019-07-27T22:05:50.240591Z"
    }
   },
   "outputs": [],
   "source": [
    "weekdays = ['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag', 'Sonntag']\n",
    "home = 'http://www.stromboli.at'\n",
    "event_site = '/index.php/programm'\n",
    "\n",
    "pages = []\n",
    "pages.append(home + event_site)\n",
    "\n",
    "response = requests.get(home + event_site)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "simililarity_dic = []\n",
    "\n",
    "\n",
    "for tt in range(len(soup.select('.pagination')[0]('a'))):\n",
    "    try:\n",
    "        int(soup.select('.pagination')[0]('a')[tt].attrs['title'])\n",
    "        pages.append(home + soup.select('.pagination')[0]('a')[tt].attrs['href'])\n",
    "    except: KeyError\n",
    "\n",
    "for page in pages:\n",
    "    t.sleep(3)\n",
    "    response = requests.get(page)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    items = soup.select('h2.article-title')\n",
    "    for item in items:\n",
    "        t.sleep(0.1)\n",
    "\n",
    "        try:\n",
    "            title_list = [item.select('a')[0].get_text().strip().split()[2][5:], ' '.join(item.select('a')[0].get_text().strip().split()[3:])]\n",
    "            title = ' '.join(title_list)\n",
    "            if title[0] == '-':\n",
    "                title = title[6:]\n",
    "            if title == ' ':\n",
    "                title = soup.select('div.col-md-8')[2*i]('p')[0].get_text().strip().split('\\r')[0]\n",
    "                \n",
    "        except: AttributeError\n",
    "\n",
    "        try:\n",
    "            date = item.select('a')[0].get_text().split()[1]\n",
    "            day, month, year = int(date[0:2]), int(date[3:5]), int('20'+date[6:8])\n",
    "            date = datetime.datetime(year, month, day)\n",
    "            week_day = weekdays[date.weekday()]\n",
    "        except: AttributeError \n",
    "\n",
    "        try:    \n",
    "            time = item.select('a')[0].get_text().split()[2][0:5]\n",
    "        except: AttributeError \n",
    "\n",
    "        try:\n",
    "            link = home + item.select('a')[0].attrs['href']\n",
    "        except: AttributeError \n",
    "\n",
    "        try:\n",
    "            location = 'Stromboli Hall in Tirol'\n",
    "        except: AttributeError\n",
    "\n",
    "        try:\n",
    "            short = soup.select('div.col-md-8')[2*i]('p')[0].get_text().strip()\n",
    "        except: AttributeError\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        hash = hashlib.sha256()\n",
    "        hash.update(bytes(title, 'utf-8'))\n",
    "        hash.update(bytes(location, 'utf-8'))\n",
    "        hash.update(bytes(str(date), 'utf-8'))\n",
    "        hash.update(bytes(str(time), 'utf-8'))\n",
    "        \n",
    "        if type(date) == datetime.datetime:\n",
    "            events.append({\n",
    "                \"name\": title,\n",
    "                \"date\": date,\n",
    "                \"location\": location,\n",
    "                \"link\": link,\n",
    "                \"short\": short,\n",
    "                \"source\": \"Stromboli Hall in Tirol Homepage\",\n",
    "                \"identifier\": hash.hexdigest()\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:06:10.427366Z",
     "start_time": "2019-07-27T22:06:08.794253Z"
    }
   },
   "outputs": [],
   "source": [
    "final_events = []\n",
    "duplicates = []\n",
    "index = []\n",
    "similarities = []\n",
    "\n",
    "for i in range(len(events)):\n",
    "    for j in range(len(events)):\n",
    "        if events[i]['date'] == events[j]['date']:\n",
    "\n",
    "            info_1 = events[i]['name'] + ' ' + events[i]['short']\n",
    "            info_2 = events[j]['name'] + ' ' + events[j]['short']\n",
    "            information = [info_1, info_2]\n",
    "\n",
    "            vect = TfidfVectorizer(min_df=1)\n",
    "            tfidf = vect.fit_transform(information)\n",
    "\n",
    "            similarity = (tfidf * tfidf.T).A\n",
    "\n",
    "            if similarity[0][1] > 0.19 and similarity[0][1] < 0.99 and similarity[0][1] not in similarities:\n",
    "                similarities.append(similarity[0][1])\n",
    "                index.append(j)\n",
    "                duplicates.append(events[j])\n",
    "\n",
    "for i in range(len(events)):\n",
    "    if i not in index:\n",
    "        final_events.append(events[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:06:10.585381Z",
     "start_time": "2019-07-27T22:06:10.441372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 79, [57])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events), len(final_events), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:06:11.805508Z",
     "start_time": "2019-07-27T22:06:10.593365Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Event(Base):\n",
    "    __tablename__ = 'event'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    identifier = Column(String)\n",
    "    name = Column(String)\n",
    "    location = Column(String)\n",
    "    source = Column(String)\n",
    "    short = Column(String)\n",
    "    date = Column(DateTime)\n",
    "    link = Column(String)\n",
    "\n",
    "\n",
    "\n",
    "engine = create_engine('sqlite:///events_db_ue6.sqlite')\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T22:06:12.598738Z",
     "start_time": "2019-07-27T22:06:11.826630Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "# from declarations import Event, Base\n",
    "# from fhku_event_scraper import get_latest_events\n",
    "\n",
    "engine = create_engine('sqlite:///events_db_ue6.sqlite')\n",
    "Base.metadata.bind = engine\n",
    "\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()\n",
    "\n",
    "\n",
    "for event in final_events:\n",
    "    ev = session.query(Event).filter_by(identifier=event['identifier']).first()\n",
    "    \n",
    "    if not ev:\n",
    "        session.add(Event(\n",
    "            name=event['name'],\n",
    "            location=event['location'],\n",
    "            link=event['link'],\n",
    "            short=event['short'],\n",
    "            date=event['date'],\n",
    "            source=event['source'],\n",
    "            identifier=event['identifier']\n",
    "            ))\n",
    "\n",
    "        \n",
    "\n",
    "session.commit()\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
